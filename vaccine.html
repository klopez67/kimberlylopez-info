<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Data-Driven Insights into Antibody Response: An R-Based Predictive Modeling Project</title>

<script src="site_libs/header-attrs-2.28/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-6.4.2/css/all.min.css" rel="stylesheet" />
<link href="site_libs/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Home</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="experience.html">Experience</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Projects
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="vaccine.html">Predicting Flu Severity</a>
    </li>
    <li>
      <a href="SAS_project.html">Risk Factors for Cognitive Decline</a>
    </li>
    <li>
      <a href="projects.html">Breast Cancer Survival Modeling</a>
    </li>
    <li>
      <a href="asthma_project.html">Asthma &amp; Tempature Dashboard</a>
    </li>
    <li>
      <a href="influenza.html">Influenza Agent Based Modeling</a>
    </li>
  </ul>
</li>
<li>
  <a href="about.html">My CV</a>
</li>
<li>
  <a href="mailto:kp2809@cumc.columbia.edu">
    <span class="fa fa-envelope fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://www.linkedin.com/in/kimberly-palaguachi-lopez2024/">
    <span class="fab fa-linkedin"></span>
     
  </a>
</li>
<li>
  <a href="http://github.com/klopez67/">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Data-Driven Insights into Antibody
Response: An R-Based Predictive Modeling Project</h1>

</div>


<style>
body {
    font-family: 'Georgia', serif;
    inline: 1.6;
    margin: 0 20px;
}

h1, h2, h3 {
    font-family: 'Georgia', serif;
    color: #2c3e50;
    margin-bottom: 10px;
}

ul {
    margin-left: 20px;
}

blockquote {
    font-style: italic;
    color: #7f8c8d;
    padding-left: 20px;
    border-left: 5px solid #ecf0f1;
}

.table {
    width: 100%;
    margin: 20px 0;
    border-collapse: collapse;
}

.table th, .table td {
    border: 1px solid #ecf0f1;
    padding: 10px;
    text-align: left;
}

.table th {
    background-color: #f9f9f9;
}
</style>
<div id="introduction" class="section level1">
<h1><strong>Introduction</strong></h1>
<p>This study investigates the influence of clinical predictors on
experience severity of flu status among vaccinated individuals 6 months
post-vaccination. We aim to identify the most superior predictive model
for severity of flu by evaluating and comparing multiple statistical
models. The selected model will help determine which factors
significantly predict the chances of experiencing severe flu based on
individual characteristics.</p>
</div>
<div id="exploratory-data-analysis" class="section level1">
<h1><strong>Exploratory Data Analysis</strong></h1>
<pre class="r"><code>library(patchwork)
library(factoextra)
library(dplyr)
library(tidyverse)
library(vtable)
library(recipes)
library(caret)
library(ggcorrplot)
library(rsample)
library(MASS)
library(ISLR) 
library(glmnet) 
library(corrplot) 
library(ggplot2)
library(plotmo) 
library(ggrepel)
library(car)
library(pROC) 

#data import
dat = read.csv(&quot;vaccine/severe_flu.csv&quot;)
dat = dat[,2:13] #removing id 
# no missing data sum(is.na(dat))

#data cleaning
dat = dat |&gt; 
  mutate(
    gender = factor(gender, levels = c(0, 1), labels = c(&quot;Female&quot;, &quot;Male&quot;)),
    race = factor(race, levels = c(1, 2, 3, 4), labels = c(&quot;White&quot;, &quot;Asian&quot;, &quot;Black&quot;, &quot;Hispanic&quot;)),
    smoking = factor(smoking, levels = c(0, 1, 2), labels = c(&quot;Never&quot;, &quot;Former&quot;, &quot;Current&quot;)),
    diabetes = factor(diabetes, levels = c(0, 1), labels = c(&quot;No&quot;, &quot;Yes&quot;)),
    hypertension = factor(hypertension, levels = c(0, 1), labels = c(&quot;No&quot;, &quot;Yes&quot;)), 
    severe_flu = factor(severe_flu, levels = c(0,1), labels = c(&quot;No&quot;, &quot;Yes&quot;)),
    age = as.numeric(age),
    SBP = as.numeric(SBP),
    LDL = as.numeric(LDL),
    bmi = as.numeric(bmi),
    weight = as.numeric(weight),
    height = as.numeric(height))

#test and training data split 
set.seed(2)

data_split = initial_split(dat, prop = 0.7)

training_data = training(data_split)
testing_data = testing(data_split)</code></pre>
<p>This dataset contains data on 1000 participants (N =1000). There were
no missing data for any of the predictors. Table 1 shows the mean,
standard deviation for each continuous variable and the proportion
across each categorical variable. In the full dataset, there were 75% of
individuals who did not experience severe flu 6-months after vaccination
while 25% did. The distribution of age, SBP, and LDL appear to be
similar across flu severity outcome, while there are some differences in
distribution of weight, height, and bmi across flu severity status
(Figure 1). There also appears to be differences in the distribution of
continuous variables in the training data compared to testing data
(Figure 2). There is evidence of multicollinearity between weight and
bmi with a correlation of 0.71-0.69 across flu severity status (Figure
3). The proportion of individual who experience severe flu across races,
smoking status, diabetes, and hypertension do not differ drastically
(Figure 4). From the PCA – Biplot on centered and scaled data, linear
combinations of continuous variables do not separate the classes well
(Figure 5).</p>
<figure style="text-align: center;">
<figcaption style="font-size: 14px; color: #555; margin-top: 5px;">
Table 1. Summary statistics for participant characteristics
</figcaption>
<p><img src="vaccine/table1.png" style="width:50%; border:none;" alt="" /></p>
</figure>
<p><strong>10-fold cross-validation (CV)</strong> was performed across
all models in the trainControl function from caret package. For each
configuration of tuning parameters, CV randomly split the training data
into 10 equal-sized folds: 9 folds serve as the training set, and the
remaining fold works as the validation set. The summary function was set
to two class summary and class probabilities were computed for the
binary outcome of flu severity. The metric ROC was calculated for each
of the validation set folds, and the average ROC was derived from them.
To optimize model performance, this process was repeated for different
parameter configurations. The model with the highest ROC was chosen as
the best or final model to be evaluated on the test dataset.</p>
<pre class="r"><code>ctrl = trainControl(method = &quot;cv&quot;,
                     number = 10,
                    summaryFunction = twoClassSummary,
                     classProbs = TRUE)</code></pre>
<p><strong>Data Preprocessing</strong> was performed on the training
data to center, scale, and apply the optimal box cox transformation on
numeric predictors through the recipes function. This recipe was
prepared on training data through the prep function, and the bake
function was applied to the new training and testing data using the prep
from the training data.</p>
<pre class="r"><code>rec= recipe(severe_flu ~ ., data = training_data) |&gt;
  step_BoxCox(all_numeric_predictors())|&gt;
  step_center(all_numeric_predictors()) |&gt;
  step_scale(all_numeric_predictors())

# 2. Prepare the recipe on the training data
prep = prep(rec, training = training_data)
trainData_pp = bake(prep,new_data = training_data)
testData_pp = bake(prep, new_data = testing_data)

#PCA
rec_pca= recipe(severe_flu ~ ., data = training_data) |&gt;
  step_BoxCox(all_numeric_predictors())|&gt;
  step_center(all_numeric_predictors()) |&gt;
  step_scale(all_numeric_predictors())|&gt;
  step_pca(num_comp = 5)

prep_pca = prep(rec, training = training_data)
trainData_pca = bake(prep_pca,new_data = training_data)
testData_pca = bake(prep_pca, new_data = testing_data)</code></pre>
<p><strong>Random seed <code>2</code></strong> was set through the
set.seed function to ensure reproducible results. All models were
trained using the caret package which were then compared on training
data performance through resampling. The models all predicted the
outcome ‘severe flu’ status.</p>
<div id="dimension-reduction" class="section level2">
<h2>Dimension Reduction</h2>
<p>Partial least squares investigated the optimal dimension reduction.
Elastic net for regularization and logistic regression as the simpler
model were fit on the training dataset as these methods balance
complexity and simpler models. Since the classes of flu severity were
not separable, SVM Radial Sigma was applied for higher-dimension
non-linear boundary. Ada Boosting was applied to repeatedly fit
classification trees to weighted versions of the training data and
update the weights to better classify previously misclassified
observations.</p>
<div id="partial-least-squares" class="section level3">
<h3>Partial Least Squares</h3>
<p><strong>Partial Least Squares (PLS):</strong> The model was trained
on the tuning grid of components 1:14 as the maximum number of
components in the dataset in a supervised way. Through CV, the optimal
number of components in the final model was 4 which explain the maximum
variance present for the predictor variables (Figure 6).</p>
<figure style="text-align: center;">
<figcaption style="font-size: 14px; color: #555; margin-top: 5px;">
Figure 6. Partial least squares (PLS) cross-validation results
</figcaption>
</figure>
<pre class="r"><code>set.seed(2)

pls_fit = train(severe_flu~., 
                data = trainData_pp, 
                method = &quot;pls&quot;,
                metric = &quot;ROC&quot;,
                tuneGrid = data.frame(ncomp = 1:14), 
                trControl = ctrl)

ggplot(pls_fit, highlight = TRUE)</code></pre>
<p><img src="vaccine_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
</div>
</div>
<div id="regularization" class="section level2">
<h2>Regularization</h2>
<p><strong>Elastic Net:</strong> The selected tuning grid of alpha and
lambda values were expanded through the expand.grid function where a
range of alpha values from 0 to 1 and a sequence of 100 lambda values
from exponential -5:3. The method in train control was set to “glmnet”.
After CV on the preprocessed training data, the final model had an
optimal alpha value of 0 and lambda value of 0.35 (Figure 7). All
variables were kept in the model. Variables such as age, gender: Male,
race: Black, smoking status: Former, and height each had negative
coefficients.</p>
<pre class="r"><code>set.seed(2)

enet.fit = train(severe_flu~., 
                 data = training_data,
                 method = &quot;glmnet&quot;,
                 preProcess = c(&quot;center&quot;, &quot;scale&quot;),
                 metric = &quot;ROC&quot;,
                 tuneGrid = expand.grid(alpha = seq(0, 1, length = 21),
                                        lambda = exp(seq(-5, 5, length = 100))),
                 trControl = ctrl)

#enet.fit$bestTune
#coef(enet.fit$finalModel, enet.fit$bestTune$lambda)


myCol = rainbow(25)
myPar = list(superpose.symbol = list(col = myCol),
              superpose.line = list(col = myCol)) 

#plot(enet.fit, par.settings = myPar, xTrans = log)  

# same logisitc regression on preproccessed data 
enet.fit2 = train(severe_flu~., 
                 data = trainData_pp,
                 method = &quot;glmnet&quot;,
                 metric = &quot;ROC&quot;,
                 tuneGrid = expand.grid(alpha = seq(0, 1, length = 21),
                                        lambda = exp(seq(-5, 3, length = 100))),
                 trControl = ctrl)

#enet.fit2$bestTune
#coef(enet.fit2$finalModel, enet.fit2$bestTune$lambda)</code></pre>
<figure style="text-align: center;">
<figcaption style="font-size: 14px; color: #555; margin-top: 5px;">
Figure 7. Cross Validation Plot of alpha and lambda for Elastic Net
</figcaption>
</figure>
<pre class="r"><code>plot(enet.fit2, par.settings = myPar, xTrans = log)</code></pre>
<p><img src="vaccine_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
</div>
</div>
<div id="model-training" class="section level1">
<h1><strong>Model Training</strong></h1>
<div id="simple-models" class="section level2">
<h2>Simple Models</h2>
<div id="logistic-regression" class="section level4">
<h4>1.) Logistic Regression</h4>
<p><strong>Logistic Regression:</strong> There is no tuning parameter
for this model, so the 10-fold CV was used for finding the optimal
model. The binomial family distribution was specified in the train
function to perform logistic regression. After CV on the preprocessed
training data, the final model included all predictors with negative
coefficients on the same variable as the elastic net model.</p>
<pre class="r"><code>set.seed(2)

#Logistic regression on ordinary data
log.fit = train(severe_flu~ .,
                data= training_data,
                method = &quot;glm&quot;,
                family = &quot;binomial&quot;,
                preProcess= c(&quot;center&quot;, &quot;scale&quot;),
                metric = &quot;ROC&quot;,
                trControl = ctrl)

#Logistic Regression Model on Preprocessed data 
log.fit2 = train(severe_flu~.,
                data= trainData_pp,
                method = &quot;glm&quot;,
                family = &quot;binomial&quot;,
                metric = &quot;ROC&quot;,
                trControl = ctrl)
#summary(log.fit2$finalModel)
#vif(log.fit2$finalModel)

#Logistic Regression on preprocessed data with PCA 
log.fit3 = train(rec_pca,
                data= training_data,
                method = &quot;glm&quot;,
                family = &quot;binomial&quot;,
                metric = &quot;ROC&quot;,
                trControl = ctrl)</code></pre>
</div>
<div id="lda" class="section level4">
<h4>2.) LDA</h4>
<p><strong>Linear Discriminant Analysis:</strong> LDA was fit using the
train() function with method “lda”. Since LDA does not have any
hyperparameters to tune, no tuning grid was specified and performs
supervised linear dimension reduction by finding a linear combination of
features that best separates the outcome classes. After CV, the two
outcome groups (severe vs. non-severe flu) were not well-separated along
the first linear discriminant (Figure 8).</p>
<pre class="r"><code>x= model.matrix( severe_flu ~ . ,training_data )[,-1]
y = training_data$severe_flu

set.seed(2)

#Model without transformations
model.lda=  train(x,y, 
                  preProcess= c(&quot;center&quot;, &quot;scale&quot;),
                  method = &quot;lda&quot;,
                  metric = &quot;ROC&quot;,
                  trControl = ctrl)

#Model on Preprocessed data 
x_rec= model.matrix( severe_flu ~ . ,trainData_pp )[,-1]
y_rec = trainData_pp$severe_flu

set.seed(2)
model.lda2=  train(x_rec,y_rec, 
                  method = &quot;lda&quot;,
                  metric = &quot;ROC&quot;,
                  trControl = ctrl)</code></pre>
<figure style="text-align: center;">
<figcaption style="font-size: 14px; color: #555; margin-top: 5px;">
Figure 8. Linear Discriminant Analysis Final model
</figcaption>
</figure>
<pre class="r"><code>plot(model.lda2$finalModel)</code></pre>
<p><img src="vaccine_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
</div>
</div>
<div id="advanced-models" class="section level2">
<h2>Advanced Models</h2>
<div id="classification-ada-boosting" class="section level4">
<h4>1.) Classification Ada Boosting</h4>
<p><strong>Ada Boosting:</strong> A tuning grid was created using
expand.grid, varying the number of trees (n.trees = 0.1, 1, 10, 50,
100), interaction depth (1–5), and shrinkage (0.001, 0.005, 0.01, 0.05).
The minimum number of observations in each terminal node was set to the
default value of 10. The default number of individuals in each final
node was used (10). The method was set to “gbm” for boosting and
specification of “adaboost” distribution. After CV, the optimal model
used 50 trees, 1 interaction depth, and a shrinkage of 0.01 (Figure 9).
Variable importance plots indicated that BMI had the strongest influence
on predicting flu severity, followed by weight (coefficient magnitude:
0.97), while other variables contributed very little to the model
(Figure 10).</p>
<figure style="text-align: center;">
<figcaption style="font-size: 14px; color: #555; margin-top: 5px;">
Figure 9. Cross Validation Plot for Ada Boosting
</figcaption>
</figure>
<pre class="r"><code>gbmA.grid = expand.grid(n.trees = c(0.1,1,10,100,200), 
                        interaction.depth = 1:5,
                        shrinkage = c(0.001,0.005, 0.01, 0.05), 
                        n.minobsinnode = 10)
set.seed(2)

#Ada Boosting on non-scaled data wihout highly correlated variables
gbmA.fit = train(severe_flu ~ . -weight - height, 
                  data= training_data, 
                  tuneGrid = gbmA.grid,
                  trControl = ctrl,
                  method = &quot;gbm&quot;,
                  distribution = &quot;adaboost&quot;,
                  metric = &quot;ROC&quot;,
                  verbose = FALSE) 

#Ada Boosting on Pre processed data
gbmA.fit2 = train(severe_flu ~ ., 
                  data= trainData_pp, 
                  tuneGrid = gbmA.grid,
                  trControl = ctrl,
                  method = &quot;gbm&quot;,
                  distribution = &quot;adaboost&quot;,
                  metric = &quot;ROC&quot;,
                  verbose = FALSE)

ggplot(gbmA.fit2, highlight = TRUE)</code></pre>
<p><img src="vaccine_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<pre class="r"><code>#summary(gbmA.fit2$finalModel, las = 2, cBars = 19, cex.names = 0.8)</code></pre>
</div>
<div id="svm-radial-sigma" class="section level4">
<h4>3.) SVM Radial Sigma</h4>
<p><strong>Support Vector Machine (SVM) Radial Sigma:</strong> This
model used the specified method of “svmRadialSigma”. The hyperparameter
grid was defined with an exponential range of cost (C) values from
exp(3) to exp(7), totaling 25 values, and sigma values from exp(−12) to
exp(−4), totaling 15 values. This expanded grid was selected based on
prior experimentation with the grid, as smaller ranges (e.g., C between
exp(0) and exp(5)) were at the boundaries of the previous grids. After
CV, the optimal model used a cost value of 175.32 and sigma value of
6.041424e-05 (Figure 11).</p>
<pre class="r"><code>plot(svmr.fit2, highlight = TRUE, par.settings = myPar)</code></pre>
<p><img src="vaccine_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
</div>
</div>
</div>
<div id="model-selection" class="section level1">
<h1><strong>Model selection</strong></h1>
<p>To compare the models, the resamples function was applied since the
same CV and data preprocessing was applied to each model. The model with
the highest median ROC on the training data was logistic regression
(0.738). All models had similarly high sensitivity, the ability to
correctly identify severe flu cases, and low specificity, indicating
limited ability to correctly classify non-severe cases. The logistic
regression had a specificity of 0.21 and sensitivity of 0.95. Although
the elastic net model, which behaved more like a ridge regression (α =
0), achieved the highest mean ROC (0.710), it did not have the highest
median ROC, suggesting less consistent performance across folds.</p>
<p>Figure 12. Resampling Cross-Validation Model Comparison</p>
<pre class="r"><code>#*scaled, centered &amp; box cox transformation*
resamp = resamples(list(svmr2= svmr.fit2, 
                        boosting2= gbmA.fit2,
                        pls = pls_fit,
                        enet2= enet.fit2,
                        lda2 = model.lda2,
                        logistic2= log.fit2, 
                        logistic3= log.fit3)) # Pca logistic 
#summary(resamp)
bwplot(resamp)</code></pre>
<p><img src="vaccine_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>Across many models, variables such as bmi, weight, and height were
highly correlated. PCA was applied to the final model as an attempt to
reduce the differences in variances, but did not improve the model on
the training data (log.fit3). The final model did not use PCA as it did
not improve generalizability, so to preserve interpretability, simple
logistic regression was used. Therefore, the final model of logistic
regression trained on the preprocessed data was selected based on the
lowest median ROC selection criteria. Thus, advanced methods such as
boosting and SVM did not outperform simpler logistic regression,
suggesting limited benefit from more complex models in this dataset.</p>
</div>
<div id="results" class="section level1">
<h1><strong>Results</strong></h1>
<p>The odds ratio of flu severity is e^0.51= 1.66 among males (p=
0.0077) compared to females, holding all other variables fixed. This
result is statistically significant. The odds ratio of flu severity is
1.2 among Asian individuals, lower among Black individuals, and 1.5
times higher among Hispanic individuals compared to white individuals.
The OR of flu severity among former smokers is 0.25 lower compared to
those who never smoked and 1.93 times higher among current smokers (p=
0.029). Each additional year of age was associated with a 3% decrease in
the odds of severe flu (OR = exp(-0.126) = 0.88), but this was not
statistically significant (p = 0.2402). Each unit increase in BMI is
associated with 2.18 higher OR of experiencing a severe flu, holding all
variable fixed (p &lt;0.001). Those who have diabetes had 1.66 times the
odds of experiencing severe flu compared to those who do not have
diabetes (p= 0.053). The OR of flu severity among those with
hypertension was 1.46 higher than those who do not have hypertension (p
= 0.23). Each unit increase in Systolic blood pressure was associated
with 1.07 times the odds of flu severity (p= 0.68). Each unit increase
in LDL cholesterol levels was associated with 1.16 times the odds of flu
severity while holding all other variables fixed (p= 0.11). The only
coefficients which were found to be significant with the outcome of flu
severity was gender (Male), smoking status (Current), and BMI. These
results suggest that BMI, gender, and smoking status are the most
relevant predictors in this dataset, while many clinical variables such
as SBP and LDL had low predictive information. By inputting individual
participant values for variables such as age, gender, race, smoking
status, and other health conditions, the logistic regression equation
produces a probability that quantifies the risk of experiencing severe
flu.</p>
<p>The final model had lower test performance (ROC= 0.68) compared to
the training performance (ROC = 0.738). The model may have had poor
generalizability due to differences in distributions of continuous
predictors in training and testing data. Variable importance plots of
models and optimal number of components also suggested that many of
these predictors were not significant in explaining the variance of
outcome.</p>
<p>The final model had a kappa value of 0.2 and accuracy of 0.75 which
suggests the model has poor observed and expected agreement. Values of
kappa close to 0 suggest the models are uncorrelated and classification
is not meaningful in the data.</p>
<p>Boosting and SVM models did not perform better on the training data.
This was likely due to the classes not being nearly separable and
overlapping substantially, so SVM performed poor compared to logistic
regression. Boosting did not perform well even when highly correlated
variables were excluded from the train function. Overall, the predictor
variables in this data may not have been truly informative of the
outcome of flu severity 6-months post-vaccination evident of low
importance among majority of predictors.</p>
<p>Figure 12. Resampling Cross-Validation Model Comparison</p>
<pre class="r"><code># Predict probabilities for the &quot;Yes&quot; class (severe flu)
test.pred.prob = predict(log.fit2, newdata = testData_pp, type = &quot;prob&quot;)[, &quot;Yes&quot;]

test.pred = ifelse(test.pred.prob &gt; 0.5, &quot;Yes&quot;, &quot;No&quot;)

confusion_table= confusionMatrix(data = factor(test.pred, levels = c(&quot;No&quot;, &quot;Yes&quot;)),
                reference = testData_pp$severe_flu,
                positive = &quot;Yes&quot;)

roc.glm = roc(testData_pp$severe_flu, test.pred.prob)</code></pre>
<pre><code>## Setting levels: control = No, case = Yes</code></pre>
<pre><code>## Setting direction: controls &lt; cases</code></pre>
<pre class="r"><code># ROC curve
plot(roc.glm, legacy.axes = TRUE, print.auc = TRUE)</code></pre>
<p><img src="vaccine_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
</div>
<div id="appendix" class="section level1">
<h1><strong>Appendix</strong></h1>
<figure style="text-align: center;">
<figcaption style="font-size: 14px; color: #555; margin-top: 5px;">
Figure 1. Density plots of the distribution of continuous variables
across the outcome of flu severity in the Training data
</figcaption>
</figure>
<pre class="r"><code>par(mfrow = c(2, 4))  

cont_pred = c(&quot;age&quot;, &quot;height&quot;, &quot;weight&quot;, &quot;bmi&quot;, &quot;SBP&quot;, &quot;LDL&quot;)
plot_list = list()

# Loop over each variable
for (var in cont_pred) {
  p = ggplot(training_data, aes_string(x = &quot;severe_flu&quot;, y = var)) +
    geom_violin(trim = FALSE) +
    geom_boxplot(width = 0.1, outlier.shape = NA) 
  
  plot_list[[var]] = p
}

wrap_plots(plot_list, ncol = 3)</code></pre>
<p><img src="vaccine_files/figure-html/unnamed-chunk-16-1.png" width="960" /></p>
<figure style="text-align: center;">
<figcaption style="font-size: 14px; color: #555; margin-top: 5px;">
Figure 2. Density plots of the distribution of continuous variables
across the outcome of flu severity in the Testing data
</figcaption>
</figure>
<pre class="r"><code>par(mfrow = c(2, 4))  

for (var in cont_pred) {
  p = ggplot(testing_data, aes_string(x = &quot;severe_flu&quot;, y = var)) +
    geom_violin(trim = FALSE) +
    geom_boxplot(width = 0.1, outlier.shape = NA) 
  
  plot_list[[var]] = p
}

wrap_plots(plot_list, ncol = 3)</code></pre>
<p><img src="vaccine_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<figure style="text-align: center;">
<figcaption style="font-size: 14px; color: #555; margin-top: 5px;">
Figure 3. Correlation heatmap of continuous predictors across the flu
severity status
</figcaption>
</figure>
<pre class="r"><code>#for no severe_flu group
dat_0= dat|&gt;
  filter(severe_flu == &quot;Yes&quot;)
cor_data_0=  dat_0[cont_pred]
cor_matrix_0= cor(cor_data_0)

# for severe_flu group
dat_1= dat|&gt;
  filter(severe_flu == &quot;No&quot;)
cor_data_1 = dat_1[cont_pred]
cor_matrix_1= cor(cor_data_1)

corr_0= ggcorrplot(cor_matrix_0,
           hc.order = TRUE,
           type = &quot;lower&quot;,
           lab = TRUE,
           colors = c(&quot;red&quot;, &quot;white&quot;, &quot;blue&quot;),
           ggtheme = theme_minimal())

corr_1= ggcorrplot(cor_matrix_1,
           hc.order = TRUE,
           type = &quot;lower&quot;,
           lab = TRUE,
           colors = c(&quot;red&quot;, &quot;white&quot;, &quot;blue&quot;),
           ggtheme = theme_minimal())

corr_0+corr_1</code></pre>
<p><img src="vaccine_files/figure-html/unnamed-chunk-18-1.png" width="960" /></p>
<figure style="text-align: center;">
<figcaption style="font-size: 14px; color: #555; margin-top: 5px;">
Figure 4. Bar plots of discrete predictors across flu severity status
</figcaption>
</figure>
<pre class="r"><code>cat_pred = c(&quot;race&quot;, &quot;smoking&quot;, &quot;diabetes&quot;, &quot;hypertension&quot;)
plot_list = list()

for (var in cat_pred) {
  p = ggplot(dat, aes(x = .data[[var]], fill = factor(severe_flu))) +
    geom_bar(position = &quot;fill&quot;) +
    labs(x = var, y = &quot;Proportion&quot;, fill = &quot;Severe Flu&quot;) +
    theme_minimal()
  
  plot_list[[var]] = p
}

wrap_plots(plot_list, ncol = 2)</code></pre>
<p><img src="vaccine_files/figure-html/unnamed-chunk-19-1.png" width="960" /></p>
<figure style="text-align: center;">
<figcaption style="font-size: 14px; color: #555; margin-top: 5px;">
Figure 5. Principle Component Analysis – Biplot of PC1 and PC2 across
flu severity
</figcaption>
</figure>
<pre class="r"><code>#biplot
train_numeric= trainData_pp |&gt; 
              dplyr::select(where(is.numeric))

pca.fit = prcomp(train_numeric)
fviz_pca_biplot(pca.fit, 
                axes = c(1,2),
                habillage = trainData_pp$severe_flu, 
                addEllipses = TRUE ,
                label = &quot;none&quot;)</code></pre>
<p><img src="vaccine_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3,h4",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
